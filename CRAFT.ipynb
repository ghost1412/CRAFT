{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRAFT\n",
    "\n",
    "## Speech to animation using CRAFT Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load\n",
    "\n",
    "Load Dataset and annotations and Test Train Val split json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "def load():\n",
    "    print(\"Loading annotations .... \", end='')\n",
    "    with open('flintstones_annotations_v1-0.json') as annotations:\n",
    "        flintstones_annotations = json.load(annotations)\n",
    "    print(\"done\")\n",
    "\n",
    "    print(\"Loading test train val split files .... \", end='')\n",
    "    with open('train-val-test_split.json') as split:\n",
    "        train_val_test_split = json.load(split)\n",
    "    print(\"done\")\n",
    "return flintstones_annotations, train_val_test_split\n",
    "\n",
    "def trainData(train_val_test_split):\n",
    "    train = []\n",
    "    for file in train_val_test_split['train']:\n",
    "        video = np.load('flintstones_dataset/video_frames/'+file+'.npy')\n",
    "        train.append(video)\n",
    "    return np.array(train)\n",
    "\n",
    "def valData(train_val_test_split):\n",
    "    val = []\n",
    "    for file in train_val_test_split['val']:\n",
    "        video = np.load('flintstones_dataset/video_frames/'+file+'.npy')\n",
    "        val.append(video)\n",
    "    return np.array(val)\n",
    "\n",
    "def testData(train_val_test_split):\n",
    "    test = []\n",
    "    for file in train_val_test_split['test']:\n",
    "        video = np.load('flintstones_dataset/video_frames/'+file+'.npy')\n",
    "        test.append(video)\n",
    "    return np.array(test)\n",
    "\n",
    "def getVideo(name):\n",
    "    return np.load('flintstones_dataset/video_frames/'+name+'.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "MAX_LEN = 75  # Max length of review (in words)\n",
    "\n",
    "def preProcessData():\n",
    "    annotation, trainTest = load()\n",
    "    data = []\n",
    "    words = []\n",
    "    tags = []\n",
    "    sentences = []\n",
    "    sentences_tag = []\n",
    "    #sentences.append([])\n",
    "    for i in range(len(annotation)):\n",
    "        data.append(annotation[i][\"parse\"][\"pos_tags\"])\n",
    "\n",
    "    for i in range(len(annotation)):\n",
    "        sentences.append([])\n",
    "        sentences_tag.append([])\n",
    "        for j in range(len(annotation[i][\"parse\"][\"pos_tags\"])):\n",
    "            words.append(annotation[i][\"parse\"][\"pos_tags\"][j][0])\t\n",
    "            sentences[i].append(annotation[i][\"parse\"][\"pos_tags\"][j][0])\n",
    "            sentences_tag[i].append(annotation[i][\"parse\"][\"pos_tags\"][j][1])\n",
    "            tags.append(annotation[i][\"parse\"][\"pos_tags\"][j][1])\n",
    "    words = list(set(words))\n",
    "    tags = list(set(tags))\n",
    "\n",
    "    word2idx = {w: i + 2 for i, w in enumerate(words)}\n",
    "    word2idx[\"UNK\"] = 1 # Unknown words\n",
    "    word2idx[\"PAD\"] = 0 # Padding\n",
    "\n",
    "    idx2word = {i: w for w, i in word2idx.items()}\n",
    "\n",
    "    tag2idx = {t: i+1 for i, t in enumerate(tags)}\n",
    "    tag2idx[\"PAD\"] = 0\n",
    "\n",
    "    idx2tag = {i: w for w, i in tag2idx.items()}\n",
    "    print(\"Barney walks into the dining room and takes an apple out of a pig's mouth. The pig wakes up and speaks to him.: {}\".format(word2idx[\"Barney\"]))\n",
    "\n",
    "    from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "    # Convert each sentence from list of Token to list of word_index\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(sentences)):\n",
    "        X.append([])\n",
    "        for j in range(len(sentences[i])):\n",
    "            X[i].append(word2idx[sentences[i][j]])\n",
    "\n",
    "    X = pad_sequences(maxlen=MAX_LEN, sequences=X, padding=\"post\", value=word2idx[\"PAD\"])\n",
    "\n",
    "    for i in range(len(sentences)):\n",
    "        y.append([])\n",
    "        for j in range(len(sentences_tag[i])):\n",
    "            y[i].append(tag2idx[sentences_tag[i][j]])\n",
    "\n",
    "    y = pad_sequences(maxlen=MAX_LEN, sequences=y, padding=\"post\", value=tag2idx[\"PAD\"])\n",
    "    print(len(tags))\n",
    "    from keras.utils import to_categorical\n",
    "    # One-Hot encode\n",
    "    y = [to_categorical(i, num_classes=len(tags)+1) for i in y]  # n_tags+1(PAD)\n",
    "\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1)\n",
    "    X_tr.shape, X_te.shape, np.array(y_tr).shape, np.array(y_te).shape\n",
    "    return X_tr, X_te, y_tr, y_te, len(words), len(tags), idx2tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading annotations .... done\n",
      "Loading test train val split files .... done\n",
      "Barney walks into the dining room and takes an apple out of a pig's mouth. The pig wakes up and speaks to him.: 1135\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "# %load lstm.py\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from keras_contrib.layers import CRF\n",
    "import numpy as np\n",
    "\n",
    "BATCH_SIZE = 512  # Number of examples used in each iteration\n",
    "EPOCHS = 1  # Number of passes through entire dataset\n",
    "MAX_LEN = 75  # Max length of review (in words)\n",
    "EMBEDDING = 40  # Dimension of word embedding vector\n",
    "\n",
    "\n",
    "def lstm():\n",
    "\n",
    "    input = Input(shape=(MAX_LEN,))\n",
    "    model = Embedding(input_dim=n_words+2, output_dim=EMBEDDING, # n_words + 2 (PAD & UNK)\n",
    "                  input_length=MAX_LEN, mask_zero=True)(input)  # default: 20-dim embedding\n",
    "    model = Bidirectional(LSTM(units=100, return_sequences=True,\n",
    "                           recurrent_dropout=0.1))(model)  # variational biLSTM\n",
    "    model = TimeDistributed(Dense(50, activation=\"relu\"))(model)  # a dense layer as suggested by neuralNer\n",
    "    crf = CRF(n_tags+1)  # CRF layer, n_tags+1(PAD)\n",
    "    out = crf(model)  # output\n",
    "    model = Model(input, out)\n",
    "    model.compile(optimizer=\"rmsprop\", loss=crf.loss_function, metrics=[crf.accuracy])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "X_tr, X_te, y_tr, y_te, n_words, n_tags, idx2tag = preProcessData()\n",
    "\n",
    "model = lstm()\n",
    "history = model.fit(X_tr, np.array(y_tr), batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=0.1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval\n",
    "pred_cat = model.predict(X_te)\n",
    "pred = np.argmax(pred_cat, axis=-1)\n",
    "y_te_true = np.argmax(y_te, -1)\n",
    "\n",
    "\n",
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "\n",
    "# Convert the index to tag\n",
    "pred_tag = [[idx2tag[i] for i in row] for row in pred]\n",
    "y_te_true_tag = [[idx2tag[i] for i in row] for row in y_te_true] \n",
    "\n",
    "report = flat_classification_report(y_pred=pred_tag, y_true=y_te_true_tag)\n",
    "print(report)\n",
    "\n",
    "\n",
    "\n",
    "i = np.random.randint(0,X_te.shape[0]) # choose a random number between 0 and len(X_te)\n",
    "p = model.predict(np.array([X_te[i]]))\n",
    "p = np.argmax(p, axis=-1)\n",
    "true = np.argmax(y_te[i], -1)\n",
    "\n",
    "print(\"Sample number {} of {} (Test Set)\".format(i, X_te.shape[0]))\n",
    "# Visualization\n",
    "print(\"{:15}||{:5}||{}\".format(\"Word\", \"True\", \"Pred\"))\n",
    "print(30 * \"=\")\n",
    "for w, t, pred in zip(X_te[i], true, p[0]):\n",
    "    if w != 0:\n",
    "        print(\"{:15}: {:5} {}\".format(words[w-2], idx2tag[t], idx2tag[pred]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import *\n",
    "\n",
    "def cnnModel(F):\n",
    "\n",
    "    CNN1 = Input((128, 128, 3*F))\n",
    "    CNN2 = Conv2D(64, kernel_size=(3, 3), strides=(2, 2), dilation_rate=(1, 1), padding='same', activation='relu')(CNN1)\n",
    "    CNN3 = Conv2D(128, kernel_size=(3, 3), strides=(2, 2), dilation_rate=(1, 1), padding='same', activation='relu')(CNN2)\n",
    "    CNN4 = Conv2D(256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(2, 2), padding='same', activation='relu')(CNN3)\n",
    "    CNN5 = Conv2D(512, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(4, 4), padding='same', activation='relu')(CNN4)\n",
    "    CNN6 = Conv2D(100, kernel_size=(1, 1), padding='same', activation='relu')(CNN5)\n",
    "    CNN7 = Conv2D(2, kernel_size=(1, 1), padding='same', activation='relu')(CNN6)\n",
    "    model = Model(inputs=CNN1, outputs=CNN7)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load layoutcomposer.py\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import *\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "from cnn import *\n",
    "import numpy as np\n",
    "\n",
    "F = 8\n",
    "\n",
    "def bilinear_kernel(h, w, channels, use_bias = True, dtype = \"float32\") :\n",
    "\n",
    "    y = np.zeros((h,w,channels,channels), dtype = dtype)\n",
    "    for i in range(0, h):\n",
    "        for j in range(0, w):\n",
    "            y[i,j,:,:] = np.identity(channels) / float(h*w*1)\n",
    "    if use_bias : return [y,np.array([0.], dtype = dtype)]\n",
    "    else : return [y]\n",
    "\n",
    "\n",
    "def channelPool(x):\n",
    "  \n",
    "    return K.max(x,axis=-1)\n",
    "\n",
    "def createModel():\n",
    "\n",
    "\n",
    "    cnn = cnnModel(F)\n",
    "    # FULLY CONV. LOCATION MLP\n",
    "    Ploc1 = Conv2D(256, kernel_size=(1, 1), padding='same', activation='relu')(cnn.layers[4].output) \n",
    "    Ploc2 = Conv2D(128, kernel_size=(1, 1), padding='same', activation='relu')(Ploc1)\n",
    "    Ploc3 = Conv2D(128, kernel_size=(1, 1), padding='same', activation='relu')(Ploc2)\n",
    "    Ploc4 = Conv2D(F, kernel_size=(1, 1), padding='same', activation='relu')(Ploc3)\n",
    "\n",
    "    # UPSAMPLING FOR LOCATION OUTPUT\n",
    "    #Ploc = UpSampling2D(size=(2, 2), data_format=None, interpolation='bilinear')\n",
    "\n",
    "    #TODO\n",
    "    Ploc = Conv2D(filters = F, kernel_size = (4, 4), strides=(1,1), \n",
    "        activation = 'softmax', padding = 'same', use_bias = False,\n",
    "        weights = bilinear_kernel(4, 4, F, False))(Ploc4)\n",
    "    #print(CNN5.shape)\n",
    "    # CHANNEL MAXPOOLING AND MERGE WITH CNN\n",
    "    #TODO\n",
    "    Max = Lambda(channelPool)(Ploc4)\n",
    "    Avg = average(cnn.output, Max)\n",
    "    # SCALE MLP\n",
    "    #TODO\n",
    "    #mu1 = Dense(256, activation='relu')(attention)\n",
    "    #mu2 = Dense(128, activation='relu')(mu1)\n",
    "    #mu3 = Desne(2*F, activation='sigmoid')(mu2)\n",
    "\n",
    "    # MODEL SUMMARY\n",
    "    model = Model(inputs=cnn.input, outputs=Max)\n",
    "    model.summary()\n",
    "    plot_model(model, to_file='LAYOUTCOMPOSER.png', show_shapes=True)\n",
    "    return model\n",
    "\n",
    "createModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load entityretriever.py\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import *\n",
    "from keras.utils import plot_model\n",
    "import numpy as np\n",
    "from cnn import *\n",
    "\n",
    "F = 8\n",
    "\n",
    "#Returns Model of Query/Target Embedding Network\n",
    "#Input: [l1,V1,l2,V2.........lF,VF]\n",
    "#Ouput: Query/Target Embeddings\n",
    "\n",
    "def EmbeddingNetwork(Entity, Query):\n",
    "    # Input\n",
    "    In = []\n",
    "\n",
    "    # CNN for Video Frames\n",
    "    cnn = []\n",
    "\n",
    "    # Ouput of CNNs\n",
    "    CNN = []\n",
    "\n",
    "    # Querry/Target Embedding CNNs\n",
    "    for i in range(F):\n",
    "        cnn.append(cnnModel(1))\n",
    "\n",
    "    # CNN Input and output\n",
    "    for i in range(F):\n",
    "        In.append(Input((128, 128, 1)))\n",
    "        In.append(cnn[i].input)\n",
    "        CNN.append(cnn[i].output)\n",
    "\n",
    "    # ROI/Global Pooling\n",
    "    #TODO\n",
    "    if Entity == True:\n",
    "        # ROI Polling\n",
    "    else:\n",
    "        # Global Polling\n",
    "\n",
    "    # Query Video Bi-LSTM\n",
    "    #TODO\n",
    "\n",
    "    # LSTM and Text LSTM Concat\n",
    "    #TODO\t\n",
    "    #concat = \n",
    "\n",
    "    # Query MLP\n",
    "    if Query == True:\n",
    "        MLP = Dense(256, activation='relu')(concat)\n",
    "        MLP = Dense(128, activation='relu')(MLP)\n",
    "\n",
    "    # L2 Normalize\n",
    "    #TODO\n",
    "\n",
    "    model = Model(inputs=In, outputs=CNN)\n",
    "    model.summary()\n",
    "    if Query == True:\n",
    "        plot_model(model, to_file='QUERYEMBEDDING.png', show_shapes=True)\n",
    "    else:\n",
    "        plot_model(model, to_file='TARGETEMBEDDING.png', show_shapes=True)\n",
    "    return model\n",
    "\n",
    "# Returns Model of Entity/Background Retriever\n",
    "# Input: [l1,V1,l2,V2, ... ,lF,VF, l1,V1,l2,V2, ... ,lF,VF]\n",
    "# OUTPUT: [q . r]\n",
    "\n",
    "def Retriever(Entity):\n",
    "    querry = QueryEmbeddingNetwork(Entity, True)\n",
    "    target = TargetEmbeddingNetwork(Entity, False)\n",
    "    model = Model(inputs=[querry.inputs target.inputs], outputs=CNN)\n",
    "    model.summary()\n",
    "    if Entity == True:\n",
    "        plot_model(model, to_file='ENTITYRETRIEVER.png', show_shapes=True)\n",
    "    else:\n",
    "        plot_model(model, to_file='BACKGROUNDRETRIEVER.png', show_shapes=True)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
